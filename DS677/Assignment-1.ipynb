{"cells":[{"cell_type":"markdown","metadata":{"id":"Tajfsk_7JY3E"},"source":["**Note to grader:** Each question consists of parts, e.g. Q1(i), Q1(ii), etc. Each part must be first graded  on a 0-4 scale, following the standard NJIT convention (A:4, B+: 3.5, B:3, C+: 2.5, C: 2, D:1, F:0). However, any given item may be worth 4 or 8 points; if an item is worth 8 points, you need to accordingly scale the 0-4 grade.\n","\n","\n","The total score must be re-scaled to 100. That should apply to all future assignments so that Canvas assigns the same weight on all assignments. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"SArgW_Vq-uTh"},"source":["# Assignment 1\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IlFM4hig-uTj"},"source":["## Preparation Steps"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"E3alYkjM-uTk"},"outputs":[],"source":["# Import all necessary python packages\n","import numpy as np\n","import torch\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GfrfDK0P-uT5"},"source":["## <font color = 'yellow'> Question 1. Basic Operations with Tensors </font>\n","\n","Your task for this question is to follow the NumPy  [**tutorial**](https://jalammar.github.io/visual-numpy/?fbclid=IwAR0tSntx5mj1aHteokRKrT4G6z77M3z0Quj40AQZ9mvKlhs2RTN3xXrc6Eo) and 'mirror' each of the operations presented in the tutorial with tensors in PyTorch. \n","\n","You may find useful to consult this PyTorch introductory [tutorial](https://jhui.github.io/2018/02/09/PyTorch-Basic-operations/), and as always the full PyTorch [documentation](https://pytorch.org/docs/stable/torch.html) is the ultimate resource.\n","\n","*(Please insert cells below for your answers )*"]},{"cell_type":"markdown","metadata":{},"source":["---\n","#### Creating Arrays"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([1, 2, 3])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["torch.tensor([1,2,3])"]},{"cell_type":"markdown","metadata":{},"source":["Use to inistalize an array's shape"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([0.5248, 0.4510, 0.7375])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["torch.ones(3)\n","torch.zeros(3)\n","torch.rand(3)\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Array Arithmetic\n","Create two arrays and then lets do some simple arithmetic."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([2., 3.])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["data = torch.tensor([1,2])\n","ones = torch.ones(2)\n","\n","#Keep in mind that the arrays must be of the same shape for this orperation to work.\n","sum = data + ones \n","\n","sum"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0., 1.]) tensor([1., 2.]) tensor([1., 2.])\n"]}],"source":["difference = data - ones\n","product = data * ones \n","quotient = data / ones \n","\n","print(difference,product,quotient)"]},{"cell_type":"markdown","metadata":{},"source":["This can also be done between a vector and a scalar value.<br>\n","This is called \"Broadcasting\""]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([1.6000, 3.2000])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["data = torch.tensor([1,2])\n","\n","scalar_transforms = data * 1.6 \n","scalar_transforms"]},{"cell_type":"markdown","metadata":{},"source":["#### Indexing Numpy Arrays\n","Same as indexing python lists"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(1) tensor(2) tensor([1, 2]) tensor([2, 3])\n"]}],"source":["data = torch.tensor([1,2,3])\n","print(data[0],data[1],data[0:2],data[1:])"]},{"cell_type":"markdown","metadata":{},"source":["#### Aggregation \n","Many more operations than listed here"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Max: 3, Min: 1, Mean: 2.0, Sum: 6, Product: 6.0, Standard Deviation: 1.0\n"]}],"source":["data = torch.tensor([1,2,3])\n","max = data.max()\n","min = data.min() \n","sum = data.sum()\n","mean = data.float().mean() \n","product = data.float().prod() \n","sd = data.float().std()\n","\n","print(f\"Max: {max}, Min: {min}, Mean: {mean}, Sum: {sum}, Product: {product}, Standard Deviation: {sd}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### In More Dimensions \n","(Arrays with more and 1 dimension)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["#Two dimension Matrix\n","# Number of brackets indicates how many dimensions\n","torch.tensor([[1,2],[3,4]])"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[0.4618, 0.0469],\n","        [0.6281, 0.9009],\n","        [0.7208, 0.3040]])"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["#((row,column))\n","# Number of parenthesis indicates how many dimensions\n","torch.ones((3,2))\n","torch.zeros((3,2))\n","torch.rand((3,2))"]},{"cell_type":"markdown","metadata":{},"source":["#### Matrix Arithmetic"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[2., 3.],\n","        [4., 5.]])"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["ones = torch.ones((2,2))\n","data = torch.tensor([[1,2],[3,4]])\n","\n","sum = ones + data\n","\n","sum"]},{"cell_type":"markdown","metadata":{},"source":["*this can be done with all of the arithmetic operators (+-*/)"]},{"cell_type":"markdown","metadata":{},"source":["We can get away with doing these arithmetic operations on matrices of different size only if the different dimension is one (e.g. the matrix has only one column or one row)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["data + ones_row = \n","tensor([[1, 2],\n","        [3, 4],\n","        [5, 6]]) \n","+ \n","tensor([1., 1.]) \n","= \n","tensor([[2., 3.],\n","        [4., 5.],\n","        [6., 7.]])\n"]}],"source":["data = torch.tensor([[1,2],[3,4],[5,6]])\n","ones_row = torch.ones(2)\n","\n","sum = data + ones_row\n","\n","print(f\"data + ones_row = \\n{data} \\n+ \\n{ones_row} \\n= \\n{sum}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Dot Product \n","A key distinction to make with arithmetic is the case of matrix multiplication using the dot product. NumPy gives every matrix a dot() method we can use to carry-out dot product operations with other matrices:<br>\n","**Matrices must have one common dimension!**"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([ 30201, 302010])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["data = torch.tensor([1,2,3])\n","powers_of_ten = torch.tensor([[1,10],[100,1000],[10000,100000]])\n","\n","dot_prod = torch.matmul(data,powers_of_ten) \n","dot_prod"]},{"cell_type":"markdown","metadata":{},"source":[">What is happening: 1x1 + 2x100 + 3x10,000 | 1x10 + 2x1,000 + 3x100,000 = 30201 | 302010"]},{"cell_type":"markdown","metadata":{},"source":["#### Matrix Indexing \n","Indexing and slicing operations become even more useful when weâ€™re manipulating matrices:<br>\n","**array[Row,Column]**"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ex1 = 2\n","ex2 = tensor([[3, 4],\n","        [5, 6]])\n","ex3 = tensor([1, 3])\n"]}],"source":["data = torch.tensor([[1,2],[3,4],[5,6]])\n","\n","#[Row,Column]- If no Row or Column value is entered it exp\n","ex1 = data[0,1] \n","\n","#Slicing\n","ex2 = data[1:3]\n","ex3 = data[0:2,0]\n","\n","\n","print(f\"ex1 = {ex1}\\nex2 = {ex2}\\nex3 = {ex3}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Matrix Aggregation\n","We can aggregate matrices the same way we aggregated vectors:<br>\n","^ This can be done with alot of other aggregation methods:)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["max = 6, min = 1, sum = 21 \n"]}],"source":["data = torch.tensor([[1,2],[3,4],[5,6]])\n","\n","max = data.max()\n","min = data.min()\n","sum = data.sum()\n","\n","print(f\"max = {max}, min = {min}, sum = {sum} \")"]},{"cell_type":"markdown","metadata":{},"source":["Not only can we aggregate all the values in a matrix, but we can also aggregate across the rows or columns by using the axis parameter:\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Axis 0 max: torch.return_types.max(\n","values=tensor([5, 6]),\n","indices=tensor([2, 2])), Axis 1 max: torch.return_types.max(\n","values=tensor([2, 4, 6]),\n","indices=tensor([1, 1, 1]))\n"]}],"source":["max_axis_0 = data.max(dim=0)\n","max_axis_1 = data.max(dim=1)\n","\n","print(f\"Axis 0 max: {max_axis_0}, Axis 1 max: {max_axis_1}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Transposing and Reshaping\n","A common need when dealing with matrices is the need to rotate them. This is often the case when we need to take the dot product of two matrices and need to align the dimension they share. NumPy arrays have a convenient property called **T** to get the transpose of a matrix:<br>"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Data:\n","tensor([[1, 2],\n","        [3, 4],\n","        [5, 6]])\n","Transposed Data:\n","tensor([[1, 3, 5],\n","        [2, 4, 6]])\n"]}],"source":["data = torch.tensor([[1,2],[3,4],[5,6]])\n","\n","t_data = data.T \n","\n","print(f\"Data:\\n{data}\\nTransposed Data:\\n{t_data}\")"]},{"cell_type":"markdown","metadata":{},"source":["In more advanced use case, you may find yourself needing to switch the dimensions of a certain matrix. This is often the case in machine learning applications where a certain model expects a certain shape for the inputs that is different from your dataset. NumPyâ€™s **reshape()** method is useful in these cases. You just pass it the new dimensions you want for the matrix. You can pass -1 for a dimension and NumPy can infer the correct dimension based on your matrix:"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Data: tensor([1, 2, 3, 4, 5, 6])\n","Reshaped Data:\n","tensor([[1, 2],\n","        [3, 4],\n","        [5, 6]]) \n"]}],"source":["data = torch.tensor([1,2,3,4,5,6])\n","\n","#Play with this:\n","reshape_data = data.reshape(3,2)\n","\n","print(f\"Data: {data}\\nReshaped Data:\\n{reshape_data} \")"]},{"cell_type":"markdown","metadata":{},"source":["#### Yet More Dimensions\n","NumPy can do everything weâ€™ve mentioned in any number of dimensions. Its central data structure is called ndarray (N-Dimensional Array) for a reason.\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[1, 2],\n","         [3, 4]],\n","\n","        [[5, 6],\n","         [7, 8]]])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["n_data = torch.tensor([[[1,2],[3,4]],[[5,6],[7,8]]]) \n","n_data"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["n_ones:\n","tensor([[[1., 1.],\n","         [1., 1.],\n","         [1., 1.]],\n","\n","        [[1., 1.],\n","         [1., 1.],\n","         [1., 1.]],\n","\n","        [[1., 1.],\n","         [1., 1.],\n","         [1., 1.]],\n","\n","        [[1., 1.],\n","         [1., 1.],\n","         [1., 1.]]])\n"]}],"source":["n_ones = torch.ones((4,3,2))\n","n_zeros = torch.zeros((4,3,2))\n","n_random = torch.rand((4,3,2))\n","\n","print(f\"n_ones:\\n{n_ones}\")"]},{"cell_type":"markdown","metadata":{},"source":["##### torch.ones((4,3,2)): 4 High, 3 Wide, 2 depth or y = 4, x = 3, z = 2 in 3D Space\n","* Note: Keep in mind that when you print a 3-dimensional NumPy array, the text output visualizes the array differently than shown here. NumPyâ€™s order for printing n-dimensional arrays is that the last axis is looped over the fastest, while the first is the slowest."]},{"cell_type":"markdown","metadata":{},"source":["#### Practical Usage<br>\n","##### Formulas<br>\n","Implementing mathematical formulas that work on matrices and vectors is a key use case to consider NumPy for. Itâ€™s why NumPy is the darling of the scientific python community. For example, consider the mean square error formula that is central to supervised machine learning models tackling regression problems:\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Mean Squared Error (MSE) is calculated as:\n","\n","$$\n","\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (Y_{\\text{prediction}_i} - Y_i)^2\n","$$\n","\n","where:\n","- \\( n \\) is the number of observations.\n","- \\( Y_{\\text{prediction}_i} \\) is the predicted value for the \\( i \\)-th observation.\n","- \\( Y_i \\) is the actual value for the \\( i \\)-th observation. \n","\n","Which results in the error value for that prediction and a score for the quality of the model.\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(1.6667)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["n = 3\n","predictions = torch.ones(3)\n","labels = torch.tensor([1,2,3])\n","\n","error = (1/n) * torch.sum(np.square(predictions-labels))\n","error"]},{"cell_type":"markdown","metadata":{},"source":["#### Data Representation<br>\n","Think of all the data types youâ€™ll need to crunch and build models around (spreadsheets, images, audioâ€¦etc). So many of them are perfectly suited for representation in an n-dimensional array:<br>\n","##### Tables and Spreadsheets\n","- A spreadsheet or a table of values is a two dimensional matrix. Each sheet in a spreadsheet can be its own variable. The most popular abstraction in python for those is the **pandas dataframe**, which actually uses NumPy and builds on top of it.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Generate some random data to play with - CSV"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["./random_data.csv has been created with 100 rows of random data.\n"]}],"source":["import csv\n","import random\n","\n","# Specify the number of rows and the file name\n","num_rows = 100\n","file_name = './random_data.csv'\n","\n","# Generate data for each column\n","data = [{'id': i, 'value1': random.random(), 'value2': random.random()} for i in range(num_rows)]\n","\n","# Write data to a CSV file\n","with open(file_name, mode='w', newline='') as file:\n","    writer = csv.DictWriter(file, fieldnames=['id', 'value1', 'value2'])\n","    writer.writeheader()\n","    writer.writerows(data)\n","\n","print(f'{file_name} has been created with {num_rows} rows of random data.')\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>value1</th>\n","      <th>value2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.018787</td>\n","      <td>0.826462</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.920879</td>\n","      <td>0.138136</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.244157</td>\n","      <td>0.758379</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.191055</td>\n","      <td>0.203947</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0.154480</td>\n","      <td>0.189564</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>95</td>\n","      <td>0.599771</td>\n","      <td>0.503856</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>96</td>\n","      <td>0.481265</td>\n","      <td>0.955024</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>97</td>\n","      <td>0.693665</td>\n","      <td>0.620967</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>98</td>\n","      <td>0.622628</td>\n","      <td>0.217780</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>99</td>\n","      <td>0.016065</td>\n","      <td>0.690879</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows Ã— 3 columns</p>\n","</div>"],"text/plain":["    id    value1    value2\n","0    0  0.018787  0.826462\n","1    1  0.920879  0.138136\n","2    2  0.244157  0.758379\n","3    3  0.191055  0.203947\n","4    4  0.154480  0.189564\n","..  ..       ...       ...\n","95  95  0.599771  0.503856\n","96  96  0.481265  0.955024\n","97  97  0.693665  0.620967\n","98  98  0.622628  0.217780\n","99  99  0.016065  0.690879\n","\n","[100 rows x 3 columns]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","df = pd.read_csv('random_data.csv')\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IllLoXxGAIIo"},"outputs":[],"source":["# For grader use only\n","\n","G = [0]*2\n","\n","\n","# insert grade here  (from 0 to 8)\n","# G[1] = \n","\n","# please justify point subtraction  s"]},{"cell_type":"markdown","metadata":{"id":"YMEcdAp3-uT-"},"source":["##  <font color = 'yellow'> Question 2. Quadratic Regression\n","\n","In the lecture we discussed a simple regression problem, where points are coming from the line $y = 2x + 1$, plus some noise.  For this question you are asked to: \n","\n","(i) Generate data points coming from a quadratic function: $ y = -x^2 + 3x +10 $, plus some noise. <br>\n","(ii) Modify the PyTorch model from the class in order for it to learn a quadratic function of the form $y = a x^2 + bx +c$. <br>\n","(iii) Train your model and report what values it computes. (Sanity check: These sould be close to -1, 3, 10)\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["https://colab.research.google.com/drive/1VfMeRBCNdTyzW4ZGBnj9AAIFXr1F2Bja?usp=drive_fs#scrollTo=eKvl7myycxoq"]},{"cell_type":"markdown","metadata":{"id":"a0ek4Ry_-uT_"},"source":["# (i)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import numpy as np\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch"]},{"cell_type":"markdown","metadata":{},"source":["### Data Generation"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RAW DATA (First 10 Samples):\n","[[10.99204476]\n"," [11.91838449]\n"," [11.66934277]\n"," [11.23882658]\n"," [10.42174692]\n"," [10.47936053]\n"," [10.31866653]\n"," [11.7964403 ]\n"," [11.36115642]\n"," [11.57267525]]\n","Training and Validation Splits:\n","x_train:[[0.77127035]\n"," [0.06355835]\n"," [0.86310343]\n"," [0.02541913]\n"," [0.73199394]\n"," [0.07404465]\n"," [0.19871568]\n"," [0.31098232]\n"," [0.47221493]\n"," [0.96958463]\n"," [0.12203823]\n"," [0.77513282]\n"," [0.80219698]\n"," [0.72960618]\n"," [0.09767211]\n"," [0.18485446]\n"," [0.15601864]\n"," [0.02058449]\n"," [0.98688694]\n"," [0.62329813]\n"," [0.70807258]\n"," [0.59789998]\n"," [0.92187424]\n"," [0.63755747]\n"," [0.28093451]\n"," [0.25877998]\n"," [0.11959425]\n"," [0.72900717]\n"," [0.94888554]\n"," [0.60754485]\n"," [0.5612772 ]\n"," [0.4937956 ]\n"," [0.18182497]\n"," [0.27134903]\n"," [0.96990985]\n"," [0.21233911]\n"," [0.18340451]\n"," [0.86617615]\n"," [0.37454012]\n"," [0.29122914]\n"," [0.80839735]\n"," [0.05808361]\n"," [0.83244264]\n"," [0.54269608]\n"," [0.77224477]\n"," [0.88721274]\n"," [0.0884925 ]\n"," [0.04522729]\n"," [0.59241457]\n"," [0.68423303]\n"," [0.71324479]\n"," [0.03438852]\n"," [0.60111501]\n"," [0.81546143]\n"," [0.44015249]\n"," [0.32518332]\n"," [0.78517596]\n"," [0.76078505]\n"," [0.49517691]\n"," [0.19967378]\n"," [0.95071431]\n"," [0.29214465]\n"," [0.13949386]\n"," [0.31171108]\n"," [0.70685734]\n"," [0.11586906]\n"," [0.35846573]\n"," [0.00552212]\n"," [0.19598286]\n"," [0.89482735]\n"," [0.45606998]\n"," [0.52475643]\n"," [0.14092422]\n"," [0.06505159]\n"," [0.17052412]\n"," [0.82873751]\n"," [0.32533033]\n"," [0.93949894]\n"," [0.33089802]\n"," [0.36636184]]\n","y_train:[[11.65095062]\n"," [10.25229075]\n"," [12.0309402 ]\n"," [10.10328033]\n"," [11.66934277]\n"," [10.23987671]\n"," [10.42461346]\n"," [10.73876879]\n"," [11.23493593]\n"," [11.8696059 ]\n"," [10.3477502 ]\n"," [11.6679378 ]\n"," [11.78153433]\n"," [11.77235292]\n"," [10.52980071]\n"," [10.73943776]\n"," [10.42174692]\n"," [10.15286997]\n"," [12.06489727]\n"," [11.52877712]\n"," [11.57267525]\n"," [11.28114921]\n"," [11.9226269 ]\n"," [11.42412465]\n"," [10.78662532]\n"," [10.78847606]\n"," [10.42668597]\n"," [11.69021487]\n"," [11.93882826]\n"," [11.6421424 ]\n"," [11.29342588]\n"," [11.15597167]\n"," [10.52212234]\n"," [10.70821065]\n"," [12.00187955]\n"," [10.64325618]\n"," [10.61344081]\n"," [11.7964403 ]\n"," [10.99204476]\n"," [10.64252151]\n"," [11.76903438]\n"," [10.31866653]\n"," [11.75139115]\n"," [11.46428349]\n"," [11.59667725]\n"," [11.97082939]\n"," [10.15141621]\n"," [10.04169394]\n"," [11.41016011]\n"," [11.56528815]\n"," [11.82069553]\n"," [10.21626527]\n"," [11.36115642]\n"," [11.81110541]\n"," [11.156878  ]\n"," [10.94851423]\n"," [11.69696206]\n"," [11.67902244]\n"," [11.12346275]\n"," [10.52488028]\n"," [11.91838449]\n"," [10.7915968 ]\n"," [10.42512857]\n"," [10.97824886]\n"," [11.64597401]\n"," [10.2627464 ]\n"," [10.97620675]\n"," [10.06873001]\n"," [10.59689855]\n"," [11.8334185 ]\n"," [11.01867305]\n"," [11.26613377]\n"," [10.24216471]\n"," [10.21667811]\n"," [10.49995168]\n"," [11.88075839]\n"," [11.02514461]\n"," [11.9458037 ]\n"," [10.76407022]\n"," [10.94140582]]\n","x_val:[[0.30461377]\n"," [0.15599452]\n"," [0.66252228]\n"," [0.10789143]\n"," [0.9093204 ]\n"," [0.30424224]\n"," [0.54671028]\n"," [0.77096718]\n"," [0.96563203]\n"," [0.59865848]\n"," [0.43194502]\n"," [0.52006802]\n"," [0.38867729]\n"," [0.07455064]\n"," [0.35675333]\n"," [0.51423444]\n"," [0.52273283]\n"," [0.04645041]\n"," [0.61185289]\n"," [0.42754102]]\n","y_val:[[10.82707478]\n"," [10.47936053]\n"," [11.45769233]\n"," [10.39475205]\n"," [11.97629092]\n"," [10.74995808]\n"," [11.39992442]\n"," [11.6295597 ]\n"," [11.77257375]\n"," [11.23882658]\n"," [11.07004774]\n"," [11.14954821]\n"," [10.9366365 ]\n"," [10.24408241]\n"," [10.81990061]\n"," [11.19803853]\n"," [11.28723871]\n"," [10.17759868]\n"," [11.49080675]\n"," [11.13394693]]\n"]}],"source":["# Data Generation\n","np.random.seed(42)\n","x = np.random.rand(100, 1)\n","y = 10 + 3 * x - x**2 + .1 * np.random.randn(100, 1)\n","print(f\"RAW DATA (First 10 Samples):\\n{y[:10]}\")\n","\n","# Shuffles the indices\n","idx = np.arange(100)\n","np.random.shuffle(idx)\n","\n","# Uses first 80 random indices for train\n","train_idx = idx[:80]\n","# Uses the remaining indices for validation\n","val_idx = idx[80:]\n","\n","# Generates train and validation sets\n","x_train, y_train = x[train_idx], y[train_idx]\n","x_val, y_val = x[val_idx], y[val_idx]\n","\n","print(f\"Training and Validation Splits:\\nx_train:{x_train}\\ny_train:{y_train}\\nx_val:{x_val}\\ny_val:{y_val}\")"]},{"cell_type":"markdown","metadata":{},"source":["# (ii)"]},{"cell_type":"markdown","metadata":{},"source":["## Quadratic Regression with Pytorch"]},{"cell_type":"markdown","metadata":{},"source":["### Defining the Quadratic Regression Class with Pytorch"]},{"cell_type":"markdown","metadata":{},"source":["#### Manual Quadratic Definition"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# This is how to create a new class for creating Polynomial Regression models.\n","\n","class ManualQuadraticRegression(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # To make \"a\", \"b\", and \"c\" real parameters of the model, we need to wrap them with nn.Parameter\n","        self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n","        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n","        self.c = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n","\n","    def forward(self, x):\n","        # Computes the outputs / predictions\n","        return self.a * x **2 + self.b * x + self.c"]},{"cell_type":"markdown","metadata":{},"source":["#### Layer Quadratic Definition"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["class LayerQuadraticRegression(nn.Module):\n","    def __init__(self):\n","        super(LayerQuadraticRegression, self).__init__()\n","        # Linear layer for the linear part (b * x + c)\n","        self.linear = nn.Linear(1, 1)\n","        # Additional parameter for the quadratic term (a * x^2)\n","        self.quadratic_term = nn.Parameter(torch.randn(1))\n","\n","    def forward(self, x):\n","        # Calculate the quadratic term and the linear term\n","        quadratic_value = self.quadratic_term * x**2\n","        linear_value= self.linear(x)\n","        # Summing the linear and quadratic terms\n","        return quadratic_value + linear_value"]},{"cell_type":"markdown","metadata":{},"source":["# (iii) \n","### Training new Quadratic Regression Class"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.FloatTensor\n"]}],"source":["# Put the data in CPU (or GPU if available)\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\n","# and then we send them to the chosen device\n","x_train_tensor = torch.from_numpy(x_train).float().to(device)\n","y_train_tensor = torch.from_numpy(y_train).float().to(device)\n","\n","# Here we can see the difference - notice that .type() is more useful\n","# since it also tells us WHERE the tensor is (device)\n","print(type(x_train), type(x_train_tensor), x_train_tensor.type())\n","\n","#Define learning rate and number of epochs for GD.\n","lr = 1e-1\n","n_epochs = 100000"]},{"cell_type":"markdown","metadata":{},"source":["#### Manual Class Training"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Initial Weights: OrderedDict([('a', tensor([0.3367])), ('b', tensor([0.1288])), ('c', tensor([0.2345]))])\n"]},{"name":"stderr","output_type":"stream","text":["/Users/christopherguarino/anaconda3/envs/env_py3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["Weights after 100000: OrderedDict([('a', tensor([-0.8111])), ('b', tensor([2.7849])), ('c', tensor([10.0506]))])\n"]}],"source":["torch.manual_seed(42)\n","\n","# Now we can create a model and send it at once to the device\n","model = ManualQuadraticRegression().to(device)\n","\n","# We can also inspect its parameters using its state_dict\n","print(f\"Initial Weights: {model.state_dict()}\")\n","\n","loss_fn = nn.MSELoss(reduction='mean')\n","optimizer = optim.SGD(model.parameters(), lr=lr)\n","\n","for epoch in range(n_epochs):\n","\n","    # This sets the model in 'training' mode. We have to use this.\n","    model.train()\n","\n","    # No more manual prediction!\n","    yhat = model(x_train_tensor)\n","\n","    loss = loss_fn(y_train_tensor, yhat)\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","print(f\"Weights after {n_epochs}: {model.state_dict()}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Layered Class Training\n","Trying the other \"more readable\" training.\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Initial Weights: OrderedDict([('quadratic_term', tensor([2.2082])), ('linear.weight', tensor([[0.8692]])), ('linear.bias', tensor([0.1872]))])\n","Weights after 0: OrderedDict([('quadratic_term', tensor([2.8084])), ('linear.weight', tensor([[1.7771]])), ('linear.bias', tensor([2.1495]))])\n","Weights after 10000: OrderedDict([('quadratic_term', tensor([-0.8020])), ('linear.weight', tensor([[2.7758]])), ('linear.bias', tensor([10.0520]))])\n","Weights after 20000: OrderedDict([('quadratic_term', tensor([-0.8111])), ('linear.weight', tensor([[2.7849]])), ('linear.bias', tensor([10.0506]))])\n","Weights after 30000: OrderedDict([('quadratic_term', tensor([-0.8111])), ('linear.weight', tensor([[2.7849]])), ('linear.bias', tensor([10.0506]))])\n","Weights after 40000: OrderedDict([('quadratic_term', tensor([-0.8111])), ('linear.weight', tensor([[2.7849]])), ('linear.bias', tensor([10.0506]))])\n","Weights after 50000: OrderedDict([('quadratic_term', tensor([-0.8111])), ('linear.weight', tensor([[2.7849]])), ('linear.bias', tensor([10.0506]))])\n","Weights after 60000: OrderedDict([('quadratic_term', tensor([-0.8111])), ('linear.weight', tensor([[2.7849]])), ('linear.bias', tensor([10.0506]))])\n","Weights after 70000: OrderedDict([('quadratic_term', tensor([-0.8111])), ('linear.weight', tensor([[2.7849]])), ('linear.bias', tensor([10.0506]))])\n","Weights after 80000: OrderedDict([('quadratic_term', tensor([-0.8111])), ('linear.weight', tensor([[2.7849]])), ('linear.bias', tensor([10.0506]))])\n","Weights after 90000: OrderedDict([('quadratic_term', tensor([-0.8111])), ('linear.weight', tensor([[2.7849]])), ('linear.bias', tensor([10.0506]))])\n","OrderedDict([('quadratic_term', tensor([-0.8111])), ('linear.weight', tensor([[2.7849]])), ('linear.bias', tensor([10.0506]))])\n"]}],"source":["def make_train_step(model, loss_fn, optimizer):\n","    # Builds function that performs a step in the train loop\n","    def train_step(x, y):\n","        # Sets model to TRAIN mode\n","        model.train()\n","        # Makes predictions\n","        yhat = model(x)\n","        # Computes loss\n","        loss = loss_fn(y, yhat)\n","        # Computes gradients\n","        loss.backward()\n","        # Updates parameters and zeroes gradients\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        # Returns the loss\n","        return loss.item()\n","\n","    # Returns the function that will be called inside the train loop\n","    return train_step\n","\n","#Create the model\n","model = LayerQuadraticRegression().to(device)\n","print(f\"Initial Weights: {model.state_dict()}\")\n","\n","loss_fn = nn.MSELoss(reduction='mean')\n","optimizer = optim.SGD(model.parameters(), lr=lr)\n","\n","# Creates the train_step function for our model, loss function and optimizer\n","train_step = make_train_step(model, loss_fn, optimizer)\n","losses = []\n","\n","# For each epoch...\n","for epoch in range(n_epochs):\n","    # Performs one train step and returns the corresponding loss\n","    loss = train_step(x_train_tensor, y_train_tensor)\n","    losses.append(loss)\n","    if epoch % 10000 == 0:\n","        print(f\"Weights after {epoch}: {model.state_dict()}\")\n","\n","# Checks model's parameters\n","print(model.state_dict())"]},{"cell_type":"markdown","metadata":{},"source":["### Polynomial Quadratic Regression appears to have returned close to the expected weights after 100,000 epochs.<br>\n","#### Expected: a = -1.0, b = 3.0, c = 10.0<br>Returned: a = -0.8111, b = 2.7849, c = 10.0506\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sBjMZF1wGaUp"},"outputs":[],"source":["# for grader use only\n","\n","# insert grade here  \n","# part (i): 4, part(ii) 8, part (iii) 8\n","\n","# G[2] = \n","#\n","# please justify point subtractions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EZHVWBIjIuoy"},"outputs":[],"source":["# total score\n","max_score = 36\n","final_score = sum(G)*(100/max_score)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
