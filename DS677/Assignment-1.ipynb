{"cells":[{"cell_type":"markdown","metadata":{"id":"Tajfsk_7JY3E"},"source":["**Note to grader:** Each question consists of parts, e.g. Q1(i), Q1(ii), etc. Each part must be first graded  on a 0-4 scale, following the standard NJIT convention (A:4, B+: 3.5, B:3, C+: 2.5, C: 2, D:1, F:0). However, any given item may be worth 4 or 8 points; if an item is worth 8 points, you need to accordingly scale the 0-4 grade.\n","\n","\n","The total score must be re-scaled to 100. That should apply to all future assignments so that Canvas assigns the same weight on all assignments. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"SArgW_Vq-uTh"},"source":["# Assignment 1\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IlFM4hig-uTj"},"source":["## Preparation Steps"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"E3alYkjM-uTk"},"outputs":[],"source":["# Import all necessary python packages\n","import numpy as np\n","import torch\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GfrfDK0P-uT5"},"source":["## <font color = 'blue'> Question 1. Basic Operations with Tensors </font>\n","\n","Your task for this question is to follow the NumPy  [**tutorial**](https://jalammar.github.io/visual-numpy/?fbclid=IwAR0tSntx5mj1aHteokRKrT4G6z77M3z0Quj40AQZ9mvKlhs2RTN3xXrc6Eo) and 'mirror' each of the operations presented in the tutorial with tensors in PyTorch. \n","\n","You may find useful to consult this PyTorch introductory [tutorial](https://jhui.github.io/2018/02/09/PyTorch-Basic-operations/), and as always the full PyTorch [documentation](https://pytorch.org/docs/stable/torch.html) is the ultimate resource.\n","\n","*(Please insert cells below for your answers )*"]},{"cell_type":"markdown","metadata":{},"source":["---\n","#### Creating Arrays"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"4po5m-tq-uT6"},"outputs":[{"data":{"text/plain":["array([1, 2, 3])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["np.array([1,2,3])"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([1, 2, 3])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["torch.tensor([1,2,3])"]},{"cell_type":"markdown","metadata":{},"source":["Use to inistalize an array's shape"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([0.5248, 0.4510, 0.7375])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["torch.ones(3)\n","torch.zeros(3)\n","torch.rand(3)\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Array Arithmetic\n","Create two arrays and then lets do some simple arithmetic."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([2., 3.])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["data = torch.tensor([1,2])\n","ones = torch.ones(2)\n","\n","#Keep in mind that the arrays must be of the same shape for this orperation to work.\n","sum = data + ones \n","\n","sum"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0., 1.]) tensor([1., 2.]) tensor([1., 2.])\n"]}],"source":["difference = data - ones\n","product = data * ones \n","quotient = data / ones \n","\n","print(difference,product,quotient)"]},{"cell_type":"markdown","metadata":{},"source":["This can also be done between a vector and a scalar value.<br>\n","This is called \"Broadcasting\""]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([1.6000, 3.2000])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["data = torch.tensor([1,2])\n","\n","scalar_transforms = data * 1.6 \n","scalar_transforms"]},{"cell_type":"markdown","metadata":{},"source":["#### Indexing Numpy Arrays\n","Same as indexing python lists"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(1) tensor(2) tensor([1, 2]) tensor([2, 3])\n"]}],"source":["data = torch.tensor([1,2,3])\n","print(data[0],data[1],data[0:2],data[1:])"]},{"cell_type":"markdown","metadata":{},"source":["#### Aggregation \n","Many more operations than listed here"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Max: 3, Min: 1, Mean: 2.0, Sum: 6, Product: 6.0, Standard Deviation: 1.0\n"]}],"source":["data = torch.tensor([1,2,3])\n","max = data.max()\n","min = data.min() \n","sum = data.sum()\n","mean = data.float().mean() \n","product = data.float().prod() \n","sd = data.float().std()\n","\n","print(f\"Max: {max}, Min: {min}, Mean: {mean}, Sum: {sum}, Product: {product}, Standard Deviation: {sd}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### In More Dimensions \n","(Arrays with more and 1 dimension)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["#Two dimension Matrix\n","# Number of brackets indicates how many dimensions\n","torch.tensor([[1,2],[3,4]])"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[0.4618, 0.0469],\n","        [0.6281, 0.9009],\n","        [0.7208, 0.3040]])"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["#((row,column))\n","# Number of parenthesis indicates how many dimensions\n","torch.ones((3,2))\n","torch.zeros((3,2))\n","torch.rand((3,2))"]},{"cell_type":"markdown","metadata":{},"source":["#### Matrix Arithmetic"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[2., 3.],\n","        [4., 5.]])"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["ones = torch.ones((2,2))\n","data = torch.tensor([[1,2],[3,4]])\n","\n","sum = ones + data\n","\n","sum"]},{"cell_type":"markdown","metadata":{},"source":["*this can be done with all of the arithmetic operators (+-*/)"]},{"cell_type":"markdown","metadata":{},"source":["We can get away with doing these arithmetic operations on matrices of different size only if the different dimension is one (e.g. the matrix has only one column or one row)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["data + ones_row = \n","tensor([[1, 2],\n","        [3, 4],\n","        [5, 6]]) \n","+ \n","tensor([1., 1.]) \n","= \n","tensor([[2., 3.],\n","        [4., 5.],\n","        [6., 7.]])\n"]}],"source":["data = torch.tensor([[1,2],[3,4],[5,6]])\n","ones_row = torch.ones(2)\n","\n","sum = data + ones_row\n","\n","print(f\"data + ones_row = \\n{data} \\n+ \\n{ones_row} \\n= \\n{sum}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Dot Product \n","A key distinction to make with arithmetic is the case of matrix multiplication using the dot product. NumPy gives every matrix a dot() method we can use to carry-out dot product operations with other matrices:<br>\n","**Matrices must have one common dimension!**"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([ 30201, 302010])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["data = torch.tensor([1,2,3])\n","powers_of_ten = torch.tensor([[1,10],[100,1000],[10000,100000]])\n","\n","dot_prod = torch.matmul(data,powers_of_ten) \n","dot_prod"]},{"cell_type":"markdown","metadata":{},"source":[">What is happening: 1x1 + 2x100 + 3x10,000 | 1x10 + 2x1,000 + 3x100,000 = 30201 | 302010"]},{"cell_type":"markdown","metadata":{},"source":["#### Matrix Indexing \n","Indexing and slicing operations become even more useful when we’re manipulating matrices:<br>\n","**array[Row,Column]**"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ex1 = 2\n","ex2 = tensor([[3, 4],\n","        [5, 6]])\n","ex3 = tensor([1, 3])\n"]}],"source":["data = torch.tensor([[1,2],[3,4],[5,6]])\n","\n","#[Row,Column]- If no Row or Column value is entered it exp\n","ex1 = data[0,1] \n","\n","#Slicing\n","ex2 = data[1:3]\n","ex3 = data[0:2,0]\n","\n","\n","print(f\"ex1 = {ex1}\\nex2 = {ex2}\\nex3 = {ex3}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Matrix Aggregation\n","We can aggregate matrices the same way we aggregated vectors:<br>\n","^ This can be done with alot of other aggregation methods:)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["max = 6, min = 1, sum = 21 \n"]}],"source":["data = torch.tensor([[1,2],[3,4],[5,6]])\n","\n","max = data.max()\n","min = data.min()\n","sum = data.sum()\n","\n","print(f\"max = {max}, min = {min}, sum = {sum} \")"]},{"cell_type":"markdown","metadata":{},"source":["Not only can we aggregate all the values in a matrix, but we can also aggregate across the rows or columns by using the axis parameter:\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Axis 0 max: torch.return_types.max(\n","values=tensor([5, 6]),\n","indices=tensor([2, 2])), Axis 1 max: torch.return_types.max(\n","values=tensor([2, 4, 6]),\n","indices=tensor([1, 1, 1]))\n"]}],"source":["max_axis_0 = data.max(dim=0)\n","max_axis_1 = data.max(dim=1)\n","\n","print(f\"Axis 0 max: {max_axis_0}, Axis 1 max: {max_axis_1}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Transposing and Reshaping\n","A common need when dealing with matrices is the need to rotate them. This is often the case when we need to take the dot product of two matrices and need to align the dimension they share. NumPy arrays have a convenient property called **T** to get the transpose of a matrix:<br>"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Data:\n","tensor([[1, 2],\n","        [3, 4],\n","        [5, 6]])\n","Transposed Data:\n","tensor([[1, 3, 5],\n","        [2, 4, 6]])\n"]}],"source":["data = torch.tensor([[1,2],[3,4],[5,6]])\n","\n","t_data = data.T \n","\n","print(f\"Data:\\n{data}\\nTransposed Data:\\n{t_data}\")"]},{"cell_type":"markdown","metadata":{},"source":["In more advanced use case, you may find yourself needing to switch the dimensions of a certain matrix. This is often the case in machine learning applications where a certain model expects a certain shape for the inputs that is different from your dataset. NumPy’s **reshape()** method is useful in these cases. You just pass it the new dimensions you want for the matrix. You can pass -1 for a dimension and NumPy can infer the correct dimension based on your matrix:"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Data: tensor([1, 2, 3, 4, 5, 6])\n","Reshaped Data:\n","tensor([[1, 2],\n","        [3, 4],\n","        [5, 6]]) \n"]}],"source":["data = torch.tensor([1,2,3,4,5,6])\n","\n","#Play with this:\n","reshape_data = data.reshape(3,2)\n","\n","print(f\"Data: {data}\\nReshaped Data:\\n{reshape_data} \")"]},{"cell_type":"markdown","metadata":{},"source":["#### Yet More Dimensions\n","NumPy can do everything we’ve mentioned in any number of dimensions. Its central data structure is called ndarray (N-Dimensional Array) for a reason.\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[1, 2],\n","         [3, 4]],\n","\n","        [[5, 6],\n","         [7, 8]]])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["n_data = torch.tensor([[[1,2],[3,4]],[[5,6],[7,8]]]) \n","n_data"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["n_ones:\n","tensor([[[1., 1.],\n","         [1., 1.],\n","         [1., 1.]],\n","\n","        [[1., 1.],\n","         [1., 1.],\n","         [1., 1.]],\n","\n","        [[1., 1.],\n","         [1., 1.],\n","         [1., 1.]],\n","\n","        [[1., 1.],\n","         [1., 1.],\n","         [1., 1.]]])\n"]}],"source":["n_ones = torch.ones((4,3,2))\n","n_zeros = torch.zeros((4,3,2))\n","n_random = torch.rand((4,3,2))\n","\n","print(f\"n_ones:\\n{n_ones}\")"]},{"cell_type":"markdown","metadata":{},"source":["##### torch.ones((4,3,2)): 4 High, 3 Wide, 2 depth or y = 4, x = 3, z = 2 in 3D Space\n","* Note: Keep in mind that when you print a 3-dimensional NumPy array, the text output visualizes the array differently than shown here. NumPy’s order for printing n-dimensional arrays is that the last axis is looped over the fastest, while the first is the slowest."]},{"cell_type":"markdown","metadata":{},"source":["#### Practical Usage<br>\n","##### Formulas<br>\n","Implementing mathematical formulas that work on matrices and vectors is a key use case to consider NumPy for. It’s why NumPy is the darling of the scientific python community. For example, consider the mean square error formula that is central to supervised machine learning models tackling regression problems:\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Mean Squared Error (MSE) is calculated as:\n","\n","$$\n","\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (Y_{\\text{prediction}_i} - Y_i)^2\n","$$\n","\n","where:\n","- \\( n \\) is the number of observations.\n","- \\( Y_{\\text{prediction}_i} \\) is the predicted value for the \\( i \\)-th observation.\n","- \\( Y_i \\) is the actual value for the \\( i \\)-th observation. \n","\n","Which results in the error value for that prediction and a score for the quality of the model.\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(1.6667)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["n = 3\n","predictions = torch.ones(3)\n","labels = torch.tensor([1,2,3])\n","\n","error = (1/n) * torch.sum(np.square(predictions-labels))\n","error"]},{"cell_type":"markdown","metadata":{},"source":["#### Data Representation<br>\n","Think of all the data types you’ll need to crunch and build models around (spreadsheets, images, audio…etc). So many of them are perfectly suited for representation in an n-dimensional array:<br>\n","##### Tables and Spreadsheets\n","- A spreadsheet or a table of values is a two dimensional matrix. Each sheet in a spreadsheet can be its own variable. The most popular abstraction in python for those is the **pandas dataframe**, which actually uses NumPy and builds on top of it.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Generate some random data to play with - CSV"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["./random_data.csv has been created with 100 rows of random data.\n"]}],"source":["import csv\n","import random\n","\n","# Specify the number of rows and the file name\n","num_rows = 100\n","file_name = './random_data.csv'\n","\n","# Generate data for each column\n","data = [{'id': i, 'value1': random.random(), 'value2': random.random()} for i in range(num_rows)]\n","\n","# Write data to a CSV file\n","with open(file_name, mode='w', newline='') as file:\n","    writer = csv.DictWriter(file, fieldnames=['id', 'value1', 'value2'])\n","    writer.writeheader()\n","    writer.writerows(data)\n","\n","print(f'{file_name} has been created with {num_rows} rows of random data.')\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>value1</th>\n","      <th>value2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.018787</td>\n","      <td>0.826462</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.920879</td>\n","      <td>0.138136</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.244157</td>\n","      <td>0.758379</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.191055</td>\n","      <td>0.203947</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0.154480</td>\n","      <td>0.189564</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>95</td>\n","      <td>0.599771</td>\n","      <td>0.503856</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>96</td>\n","      <td>0.481265</td>\n","      <td>0.955024</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>97</td>\n","      <td>0.693665</td>\n","      <td>0.620967</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>98</td>\n","      <td>0.622628</td>\n","      <td>0.217780</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>99</td>\n","      <td>0.016065</td>\n","      <td>0.690879</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 3 columns</p>\n","</div>"],"text/plain":["    id    value1    value2\n","0    0  0.018787  0.826462\n","1    1  0.920879  0.138136\n","2    2  0.244157  0.758379\n","3    3  0.191055  0.203947\n","4    4  0.154480  0.189564\n","..  ..       ...       ...\n","95  95  0.599771  0.503856\n","96  96  0.481265  0.955024\n","97  97  0.693665  0.620967\n","98  98  0.622628  0.217780\n","99  99  0.016065  0.690879\n","\n","[100 rows x 3 columns]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","df = pd.read_csv('random_data.csv')\n","df"]},{"cell_type":"markdown","metadata":{},"source":["##### Audio and Timeseries\n","An audio file is a one-dimensional array of samples. Each sample is a number representing a tiny chunk of the audio signal. CD-quality audio may have 44,100 samples per second and each sample is an integer between -32767 and 32768. Meaning if you have a ten-seconds WAVE file of CD-quality, you can load it in a NumPy array with length 10 * 44,100 = 441,000 samples. Want to extract the first second of audio? simply load the file into a NumPy array that we’ll call audio, and get audio[:44100].\n","\n","##### Images\n","An image is a matrix of pixels of size (height x width).\n","\n","- If the image is black and white (a.k.a. grayscale), each pixel can be represented by a single number (commonly between 0 (black) and 255 (white)). Want to crop the top left 10 x 10 pixel part of the image? Just tell NumPy to get you image[:10,:10].\n","\n","- If the image is colored, then each pixel is represented by three numbers - a value for each of red, green, and blue. In that case we need a 3rd dimension (because each cell can only contain one number). So a colored image is represented by an ndarray of dimensions: (height x width x 3)."]},{"cell_type":"markdown","metadata":{},"source":["##### Language\n","If we’re dealing with text, the story is a little different. The numeric representation of text requires a step of building a vocabulary (an inventory of all the unique words the model knows) and an embedding step. Let us see the steps of numerically representing this (translated) quote by an ancient spirit:\n","\n","“Have the bards who preceded me left any theme unsung?”\n","\n","A model needs to look at a large amount of text before it can numerically represent the anxious words of this warrior poet. We can proceed to have it process a small dataset and use it to build a vocabulary (of 71,290 words): \n","\n","The sentence can then be broken into an array of tokens (words or parts of words based on common rules):\n","\n","We then replace each word by its id in the vocabulary table:\n","\n","These ids still don’t provide much information value to a model. So before feeding a sequence of words to a model, the tokens/words need to be replaced with their embeddings (50 dimension word2vec embedding in this case):\n","\n","You can see that this NumPy array has the dimensions [embedding_dimension x sequence_length]. In practice these would be the other way around, but I’m presenting it this way for visual consistency. For performance reasons, deep learning models tend to preserve the first dimension for batch size (because the model can be trained faster if multiple examples are trained in parallel). This is a clear case where **reshape()** becomes super useful. A model like BERT, for example, would expect its inputs in the shape: [batch_size, sequence_length, embedding_size]. \n","\n","This is now a numeric volume that a model can crunch and do useful things with. I left the other rows empty, but they’d be filled with other examples for the model to train on (or predict).\n","\n","(It turned out the poet’s words in our example were immortalized more so than those of the other poets which trigger his anxieties. Born a slave owned by his father, Antarah’s valor and command of language gained him his freedom and the mythical status of having his poem as one of seven poems suspended in the kaaba in pre-Islamic Arabia).\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IllLoXxGAIIo"},"outputs":[],"source":["# For grader use only\n","\n","G = [0]*2\n","\n","\n","# insert grade here  (from 0 to 8)\n","# G[1] = \n","\n","# please justify point subtraction  s"]},{"cell_type":"markdown","metadata":{"id":"YMEcdAp3-uT-"},"source":["##  <font color = 'yellow'> Question 2. Quadratic Regression\n","\n","In the lecture we discussed a simple regression problem, where points are coming from the line $y = 2x + 1$, plus some noise.  For this question you are asked to: \n","\n","(i) Generate data points coming from a quadratic function: $ y = -x^2 + 3x +10 $, plus some noise. <br>\n","(ii) Modify the PyTorch model from the class in order for it to learn a quadratic function of the form $y = a x^2 + bx +c$. <br>\n","(iii) Train your model and report what values it computes. (Sanity check: These sould be close to -1, 3, 10)\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["https://colab.research.google.com/drive/1VfMeRBCNdTyzW4ZGBnj9AAIFXr1F2Bja?usp=drive_fs#scrollTo=eKvl7myycxoq"]},{"cell_type":"markdown","metadata":{"id":"a0ek4Ry_-uT_"},"source":["# (i)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import sklearn\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","\n","from torchviz import make_dot"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RAW DATA (First 10 Samples):\n","[[10.99204476]\n"," [11.91838449]\n"," [11.66934277]\n"," [11.23882658]\n"," [10.42174692]\n"," [10.47936053]\n"," [10.31866653]\n"," [11.7964403 ]\n"," [11.36115642]\n"," [11.57267525]]\n","Training and Validation Splits:\n","x_train:[[0.77127035]\n"," [0.06355835]\n"," [0.86310343]\n"," [0.02541913]\n"," [0.73199394]\n"," [0.07404465]\n"," [0.19871568]\n"," [0.31098232]\n"," [0.47221493]\n"," [0.96958463]\n"," [0.12203823]\n"," [0.77513282]\n"," [0.80219698]\n"," [0.72960618]\n"," [0.09767211]\n"," [0.18485446]\n"," [0.15601864]\n"," [0.02058449]\n"," [0.98688694]\n"," [0.62329813]\n"," [0.70807258]\n"," [0.59789998]\n"," [0.92187424]\n"," [0.63755747]\n"," [0.28093451]\n"," [0.25877998]\n"," [0.11959425]\n"," [0.72900717]\n"," [0.94888554]\n"," [0.60754485]\n"," [0.5612772 ]\n"," [0.4937956 ]\n"," [0.18182497]\n"," [0.27134903]\n"," [0.96990985]\n"," [0.21233911]\n"," [0.18340451]\n"," [0.86617615]\n"," [0.37454012]\n"," [0.29122914]\n"," [0.80839735]\n"," [0.05808361]\n"," [0.83244264]\n"," [0.54269608]\n"," [0.77224477]\n"," [0.88721274]\n"," [0.0884925 ]\n"," [0.04522729]\n"," [0.59241457]\n"," [0.68423303]\n"," [0.71324479]\n"," [0.03438852]\n"," [0.60111501]\n"," [0.81546143]\n"," [0.44015249]\n"," [0.32518332]\n"," [0.78517596]\n"," [0.76078505]\n"," [0.49517691]\n"," [0.19967378]\n"," [0.95071431]\n"," [0.29214465]\n"," [0.13949386]\n"," [0.31171108]\n"," [0.70685734]\n"," [0.11586906]\n"," [0.35846573]\n"," [0.00552212]\n"," [0.19598286]\n"," [0.89482735]\n"," [0.45606998]\n"," [0.52475643]\n"," [0.14092422]\n"," [0.06505159]\n"," [0.17052412]\n"," [0.82873751]\n"," [0.32533033]\n"," [0.93949894]\n"," [0.33089802]\n"," [0.36636184]]\n","y_train:[[11.65095062]\n"," [10.25229075]\n"," [12.0309402 ]\n"," [10.10328033]\n"," [11.66934277]\n"," [10.23987671]\n"," [10.42461346]\n"," [10.73876879]\n"," [11.23493593]\n"," [11.8696059 ]\n"," [10.3477502 ]\n"," [11.6679378 ]\n"," [11.78153433]\n"," [11.77235292]\n"," [10.52980071]\n"," [10.73943776]\n"," [10.42174692]\n"," [10.15286997]\n"," [12.06489727]\n"," [11.52877712]\n"," [11.57267525]\n"," [11.28114921]\n"," [11.9226269 ]\n"," [11.42412465]\n"," [10.78662532]\n"," [10.78847606]\n"," [10.42668597]\n"," [11.69021487]\n"," [11.93882826]\n"," [11.6421424 ]\n"," [11.29342588]\n"," [11.15597167]\n"," [10.52212234]\n"," [10.70821065]\n"," [12.00187955]\n"," [10.64325618]\n"," [10.61344081]\n"," [11.7964403 ]\n"," [10.99204476]\n"," [10.64252151]\n"," [11.76903438]\n"," [10.31866653]\n"," [11.75139115]\n"," [11.46428349]\n"," [11.59667725]\n"," [11.97082939]\n"," [10.15141621]\n"," [10.04169394]\n"," [11.41016011]\n"," [11.56528815]\n"," [11.82069553]\n"," [10.21626527]\n"," [11.36115642]\n"," [11.81110541]\n"," [11.156878  ]\n"," [10.94851423]\n"," [11.69696206]\n"," [11.67902244]\n"," [11.12346275]\n"," [10.52488028]\n"," [11.91838449]\n"," [10.7915968 ]\n"," [10.42512857]\n"," [10.97824886]\n"," [11.64597401]\n"," [10.2627464 ]\n"," [10.97620675]\n"," [10.06873001]\n"," [10.59689855]\n"," [11.8334185 ]\n"," [11.01867305]\n"," [11.26613377]\n"," [10.24216471]\n"," [10.21667811]\n"," [10.49995168]\n"," [11.88075839]\n"," [11.02514461]\n"," [11.9458037 ]\n"," [10.76407022]\n"," [10.94140582]]\n","x_val:[[0.30461377]\n"," [0.15599452]\n"," [0.66252228]\n"," [0.10789143]\n"," [0.9093204 ]\n"," [0.30424224]\n"," [0.54671028]\n"," [0.77096718]\n"," [0.96563203]\n"," [0.59865848]\n"," [0.43194502]\n"," [0.52006802]\n"," [0.38867729]\n"," [0.07455064]\n"," [0.35675333]\n"," [0.51423444]\n"," [0.52273283]\n"," [0.04645041]\n"," [0.61185289]\n"," [0.42754102]]\n","y_val:[[10.82707478]\n"," [10.47936053]\n"," [11.45769233]\n"," [10.39475205]\n"," [11.97629092]\n"," [10.74995808]\n"," [11.39992442]\n"," [11.6295597 ]\n"," [11.77257375]\n"," [11.23882658]\n"," [11.07004774]\n"," [11.14954821]\n"," [10.9366365 ]\n"," [10.24408241]\n"," [10.81990061]\n"," [11.19803853]\n"," [11.28723871]\n"," [10.17759868]\n"," [11.49080675]\n"," [11.13394693]]\n"]}],"source":["# Data Generation\n","np.random.seed(42)\n","x = np.random.rand(100, 1)\n","y = 10 + 3 * x - x**2 + .1 * np.random.randn(100, 1)\n","print(f\"RAW DATA (First 10 Samples):\\n{y[:10]}\")\n","\n","# Shuffles the indices\n","idx = np.arange(100)\n","np.random.shuffle(idx)\n","\n","# Uses first 80 random indices for train\n","train_idx = idx[:80]\n","# Uses the remaining indices for validation\n","val_idx = idx[80:]\n","\n","# Generates train and validation sets\n","x_train, y_train = x[train_idx], y[train_idx]\n","x_val, y_val = x[val_idx], y[val_idx]\n","\n","print(f\"Training and Validation Splits:\\nx_train:{x_train}\\ny_train:{y_train}\\nx_val:{x_val}\\ny_val:{y_val}\")"]},{"cell_type":"markdown","metadata":{},"source":["# (ii)"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Initialized Parameters:\n","a:[0.49671415],b:[-0.1382643],c:[0.64768854]\n","Parameters after 100000 epochs:\n","a:[-0.81125085],b:[2.78508306],c:[10.05058536]\n"]}],"source":["np.random.seed(42)\n","a = np.random.randn(1)\n","b = np.random.randn(1)\n","c = np.random.randn(1)\n","\n","print(f\"Initialized Parameters:\\na:{a},b:{b},c:{c}\")\n","\n","# Sets learning rate\n","lr = 1e-1\n","# Defines number of epochs\n","n_epochs = 100000\n","\n","for epoch in range(n_epochs):\n","    # Computes our model's predicted output\n","    yhat = a * x_train**2 + b * x_train + c\n","\n","    # The error\n","    error = (y_train - yhat)\n","    # It is a regression, so it computes mean squared error (MSE)\n","    loss = (error ** 2).mean()\n","\n","    # Computes gradients for both \"a\" and \"b\" parameters\n","    a_grad = -2 * (x_train**2 * error).mean()\n","    b_grad = -2 * (x_train * error).mean()\n","    c_grad = -2 * error.mean()\n","\n","    # Updates parameters using gradients and the learning rate\n","    a = a - lr * a_grad\n","    b = b - lr * b_grad\n","    c = c - lr * c_grad\n","\n","print(f\"Parameters after {n_epochs} epochs:\\na:{a},b:{b},c:{c}\")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# (iii)"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Quadratic Model Coeffients:\n","a:-0.8112508474398796, b:2.785083060532637, c:[10.05058536] \n"]}],"source":["# Sanity Check: do we get the same results as our gradient descent?\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.linear_model import LinearRegression\n","from sklearn.pipeline import make_pipeline\n","\n","quadratic_model = make_pipeline(PolynomialFeatures(degree=2),LinearRegression())\n","\n","quadratic_model.fit(x_train, y_train)\n","# Expose the linear model in the pipeline so that we can access it's parameters. \n","linear_model = quadratic_model.named_steps['linearregression']\n","print(f\"Quadratic Model Coeffients:\\na:{linear_model.coef_[0][2]}, b:{linear_model.coef_[0][1]}, c:{linear_model.intercept_} \")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sBjMZF1wGaUp"},"outputs":[],"source":["# for grader use only\n","\n","# insert grade here  \n","# part (i): 4, part(ii) 8, part (iii) 8\n","\n","# G[2] = \n","#\n","# please justify point subtractions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EZHVWBIjIuoy"},"outputs":[],"source":["# total score\n","max_score = 36\n","final_score = sum(G)*(100/max_score)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
