{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tajfsk_7JY3E"
      },
      "source": [
        "**Note to grader:** Each question consists of parts, e.g. Q1(i), Q1(ii), etc. Each part must be first graded  on a 0-4 scale, following the standard NJIT convention (A:4, B+: 3.5, B:3, C+: 2.5, C: 2, D:1, F:0). However, any given item may be worth 4 or 8 points; if an item is worth 8 points, you need to accordingly scale the 0-4 grade.\n",
        "\n",
        "\n",
        "The total score must be re-scaled to 100. That should apply to all future assignments so that Canvas assigns the same weight on all assignments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SArgW_Vq-uTh"
      },
      "source": [
        "# Assignment 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKHAiVXNz-2i"
      },
      "source": [
        "### Preparation Steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xtT_YAhmmXs"
      },
      "source": [
        "\n",
        "\n",
        "We will work with this [mystery dataset](https://drive.google.com/open?id=1WLnWBThCYZ25pReI5DCwk2bgDaCrJxI_&authuser=ikoutis%40njit.edu&usp=drive_fs) that you can download and place to your google drive. You can then put it somewhere on your google drive and bring it into your Colab by following the steps in the following cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AMaVk7jmn_D",
        "outputId": "97c546d7-e6a1-4418-fafa-b910b5b1bdf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsLbaghZrO-L"
      },
      "source": [
        "The file contains\n",
        "\n",
        "* Two matrices $X$ and $X_1$ of numerical features. These datasets have the same dimensions (169343x80) but they are different.\n",
        "* An array $y$ of labels, ranging from 0-39.\n",
        "* The indices $otrain$ of a training set. These indices tell you what rows of the arrays $X,X_1,y$ correspond to the training points. You can use these to make two different training sets $(X[train], y[train])$ and $(X_1[train], y[train])$\n",
        "* Similarly, it contains the indexes for a validation and a test set, $ovalid$ and $otest$ respectively.\n",
        "\n",
        "The following cell shows how to access these arrays and assign them to local numpy objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HQ0Oyva2F3fF"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "\n",
        "mat = scipy.io.loadmat('mysteryDataset.mat')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALSnNeSw0JoQ"
      },
      "source": [
        "## <font color = 'blue'> Question 1. Import the dataset and conver to torch tensors </font>\n",
        "\n",
        "Your task for this question is to adapt the above preparation steps, import all mentioned variables into numpy arrays, and then transform them to PyTorch tensors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C20aEPMG0z2W"
      },
      "outputs": [],
      "source": [
        "type(mat.get('X'))\n",
        "X_feature = mat.get('X')\n",
        "X1_feature = mat.get('X1')\n",
        "y_labels = mat.get('y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Already numpy arrays. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(y_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cast to Pytorch tensors. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "X_feature = torch.tensor(X_feature)\n",
        "X1_feature = torch.tensor(X1_feature)\n",
        "y_labels = torch.tensor(y_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor Shapes:\n",
            "X: torch.Size([169343, 80])\n",
            "X1: torch.Size([169343, 80])\n",
            "y: torch.Size([169343, 1])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Tensor Shapes:\\nX: {X_feature.shape}\\nX1: {X1_feature.shape}\\ny: {y_labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBjMZF1wGaUp"
      },
      "outputs": [],
      "source": [
        "# for grader use only\n",
        "\n",
        "# insert grade here  (out of 4)\n",
        "\n",
        "# G[1] =\n",
        "#\n",
        "# please justify point subtractions when needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7I1lmGM0skC"
      },
      "source": [
        "## <font color = 'blue'> Question 2. Write a functioning classifier in PyTorch </font>\n",
        "\n",
        "Write code that defines a classification model for the above dataset, and all other functions that are needed for its training. Apply your model on the two datsets $X,X_1$ and report the accuracy. The classifier should operate on the GPU.\n",
        "\n",
        "**Hint:** Re-use code we discussed for the Softmax Regression module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "na0el-GE1qtY"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class SoftMaxRegression(nn.Module): \n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear = nn.Linear(784,10) \n",
        "\n",
        "    def forward(self,x): \n",
        "        y = self.flatten(x)\n",
        "        y = self.linear(y)\n",
        "        return y        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "device  = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = SoftMaxRegression().to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss() \n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SoftMaxRegression(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "    if type(m) ==  nn.Linear: \n",
        "        nn.init.normal_(m.weight,std=0.01)\n",
        "\n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Split bot X and X1 Datasets into Training, Validation, and Test sets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X Split\n",
        "train_data, temp_data, train_labels, temp_labels = train_test_split(\n",
        "    X_feature, y_labels, test_size=0.4, random_state=42)  \n",
        "\n",
        "validation_data, test_data, validation_labels, test_labels = train_test_split(\n",
        "    temp_data, temp_labels, test_size=0.5, random_state=42)  \n",
        "\n",
        "# X1 Split\n",
        "train_data, temp_data, train_labels, temp_labels = train_test_split(\n",
        "    X_feature, y_labels, test_size=0.4, random_state=42)  \n",
        "\n",
        "validation_data, test_data, validation_labels, test_labels = train_test_split(\n",
        "    temp_data, temp_labels, test_size=0.5, random_state=42) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_iter' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_iter\u001b[49m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x_batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y_batch)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_iter' is not defined"
          ]
        }
      ],
      "source": [
        "  for x_batch, y_batch in train_iter:\n",
        "      \n",
        "      print(x_batch.shape)\n",
        "      print(y_batch)\n",
        "\n",
        "      x_batch = x_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "      \n",
        "      y_hat = model(x_batch)\n",
        "            \n",
        "      ll = loss_fn(y_hat, y_batch )\n",
        "      print(ll)\n",
        "\n",
        "      break "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_train_step(model, loss_fn, optimizer):\n",
        "    # Builds function that performs a step in the train loop\n",
        "    def train_step(x, y):\n",
        "        # Sets model to TRAIN mode\n",
        "        model.train()\n",
        "        # Makes predictions\n",
        "        yhat = model(x)\n",
        "        # Computes loss\n",
        "        loss = loss_fn(yhat, y)\n",
        "        # Computes gradients\n",
        "        loss.backward()\n",
        "        # Updates parameters and zeroes gradients\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        # Returns the loss\n",
        "        return loss.item()\n",
        "    \n",
        "    # Returns the function that will be called inside the train loop\n",
        "    return train_step\n",
        "\n",
        "# Creates the train_step function for our model, loss function and optimizer\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "losses = []\n",
        "n_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.apply(init_weights)   #always good to initialize in the beginning\n",
        "n_epochs = 10\n",
        "losses = []\n",
        "test_losses = []\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for x_batch, y_batch in train_iter:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        loss = train_step(x_batch, y_batch)\n",
        "        losses.append(loss)\n",
        "\n",
        "    # torch no_grad makes sure that the nested-below computations happen without gradients, \n",
        "    # since these are not needed for evaluation\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_iter:\n",
        "            x_test = x_test.to(device)\n",
        "            y_test = y_test.to(device)\n",
        "            \n",
        "            model.eval()\n",
        "    \n",
        "            yhat = model(x_test)\n",
        "            test_loss = loss_fn(yhat, y_test)\n",
        "            test_losses.append(test_loss.item())\n",
        "\n",
        "#print(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_ch3(net, test_iter, n=6): \n",
        "    \"\"\"Predict labels (defined in Chapter 3).\"\"\"\n",
        "    for X, y in test_iter:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        break\n",
        "    trues = d2l.get_fashion_mnist_labels(y)\n",
        "    preds = d2l.get_fashion_mnist_labels(model(X).argmax(axis=1))\n",
        "    titles = [true + '\\n' + pred for true, pred in zip(trues, preds)]\n",
        "    Xcpu = X.cpu()\n",
        "    d2l.show_images(Xcpu[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])\n",
        "\n",
        "\n",
        "predict_ch3(model, test_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(net, test_iter):  \n",
        "    \n",
        "    n_samples = 0; \n",
        "    n_correct = 0;\n",
        "    model.eval()\n",
        "    for X, y in test_iter:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        trues = y\n",
        "\n",
        "        preds = model(X).argmax(axis=1)\n",
        "        \n",
        "\n",
        "        n_samples = n_samples + y.shape[0]\n",
        "        n_correct = n_correct + (trues==preds).sum()\n",
        "        break\n",
        "    \n",
        "    return n_correct/n_samples\n",
        "\n",
        "accuracy(model,test_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlICv7kW1qte"
      },
      "outputs": [],
      "source": [
        "# for grader use only\n",
        "\n",
        "# insert grade here  (out of 8)\n",
        "\n",
        "# G[2] =\n",
        "#\n",
        "# please justify point subtractions when needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDmA1ZZL152G"
      },
      "source": [
        "## <font color = 'blue'> Question 3. Maximize the accuracy on the two datasets </font>\n",
        "\n",
        "Augment your classifier from Question-2 with any number and type of layers you want, with the goal to maximize the **validation** accuracy you achieve on the two datasets. Feel free to use any stopping criterion you want for the training process. The networks for $X$ and $X_1$ do not have be of the same architecture.\n",
        "\n",
        "Show your code, and add a text cell summarizing your idea and findings. Finally apply your models to the **test** set, and report the accuracy. Feel free to discuss your validation accuracy on Canvas. Also please avoid looking at the test set, until the very end.\n",
        "\n",
        "**Rubric**: All complete answers get 8 points, and the **top 5** test accuracies reported get an extra 10\\% in the final quiz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySrVeueW31b_"
      },
      "outputs": [],
      "source": [
        "## your answer goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcYS1afK31cS"
      },
      "outputs": [],
      "source": [
        "# for grader use only\n",
        "\n",
        "# insert grade here  (out of 8)\n",
        "\n",
        "# G[3] =\n",
        "#\n",
        "# please justify point subtractions when needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZHVWBIjIuoy"
      },
      "outputs": [],
      "source": [
        "# total score\n",
        "max_score = 20\n",
        "$inal_score = sum(G)*(100/max_score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
